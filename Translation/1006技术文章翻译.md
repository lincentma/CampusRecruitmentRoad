# 前沿技术翻译文章

> 原文地址：https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/

> 参考译文：[一张图看懂AI、机器学习和深度学习的区别](http://news.newseed.cn/p/1326716)

> 这不仅是自己学习前沿技术的记录，也是提升英语阅读的记录，同时关注对比百度翻译、搜狗翻译、谷歌翻译三者的区别，刚好和标题中的三者的区别有异曲同工之妙。

# What’s the Difference Between Artificial Intelligence, Machine Learning, and Deep Learning?

# 如何区分人工智能，机器学习和深度学习？

This is the first of a multi-part series explaining the fundamentals of deep learning by long-time tech journalist Michael Copeland.

这是描述深度学习的基础系列的第一部分。本系列由资深科技记者迈克尔·科普兰（Michael Copeland）编写。

Artificial intelligence is the future. Artificial intelligence is science fiction. Artificial intelligence is already part of our everyday lives. All those statements are true, it just depends on what flavor of AI you are referring to.

人工智能是未来、人工智能是科幻小说、人工智能已经成为我们日常生活的一部分。所有论断都是正确的，所有的这些都已成现实，只是要看你所谈到所认为的AI到底是什么。

For example, when Google DeepMind’s AlphaGo program defeated South Korean Master Lee Se-dol in the board game Go earlier this year, the terms AI, machine learning, and deep learning were used in the media to describe how DeepMind won. And all three are part of the reason why AlphaGo trounced Lee Se-Dol. But they are not the same things.

例如，今年早些时候，Google DeepMind开发的AlphaGo程序在围棋比赛中击败韩国围棋大师李世石。媒体在报导AlphaGo获得胜利中使用人工智能、机器学习和深度学习这些术语。AlphaGo击败李世石，这些技术都立下汗马功劳，但是它们并不是同一回事。

The easiest way to think of their relationship is to visualize them as concentric circles with AI — the idea that came first — the largest, then machine learning — which blossomed later, and finally deep learning — which is driving today’s AI explosion —  fitting inside both.

同心圆是理解人工智能、机器学习和深度学习三者的关系的最简单直观的表达方式。人工智能（AI）的概念是最早出现的，同样是范围最大的；后来是机器学习的爆发式发展；最后是深度学习，正在推动着今天人工智能（AI）的爆发，两者都适合。

![](https://blogs.nvidia.com/wp-content/uploads/2016/07/Deep_Learning_Icons_R5_PNG.jpg.png)

## From Bust to Boom

## 从衰败到繁荣

AI has been part of our imaginations and simmering in research labs since a handful of computer scientists rallied around the term at the Dartmouth Conferences in 1956 and birthed the field of AI. In the decades since, AI has alternately been heralded as the key to our civilization’s brightest future, and tossed on technology’s trash heap as a harebrained notion of over-reaching propellerheads. Frankly, until 2012, it was a bit of both.

人工智能（AI）一直是我们想象力以及实验室研究的一部分，人工智能（AI）概念首先在1956年的达特茅斯会议由几位计算机科学家提出，人工智能（AI）从此诞生。在过去的几十年里，人们对人工智能（AI）的看法不断改变，有时认为人工智能（AI）是我们未来最光明文明的关键。然而有时它也被认为只是一个轻率的概念，野心过大，注定要失败，被扔进技术的垃圾堆中。坦率地说，直到2012年，人工智能（AI）这两种观念仍然同时存在。

Over the past few years AI has exploded, and especially since 2015. Much of that has to do with the wide availability of GPUs that make parallel processing ever faster, cheaper, and more powerful. It also has to do with the simultaneous one-two punch of practically infinite storage and a flood of data of every stripe (that whole Big Data movement) – images, text, transactions, mapping data, you name it.

在过去的几年里，人工智能已经发生了爆炸式增长，尤其是在2015年之后更是迅猛发展。其中很大一部分原因归功于GPU的广泛普及使用，它使并行处理变得更快、更便宜、更强大。它同时还与实际存储容量无限扩展的大环境下，各种类型的大数据不断产生有关，比如图像、文本、交易、地图数据等等你可以想到的所有数据类型。

Let’s walk through how computer scientists have moved from something of a bust — until 2012 — to a boom that has unleashed applications used by hundreds of millions of people every day.

让我们来看看计算机科学家们是如何将人工智能（AI）从萧条（直到2012年）变为繁荣，这一热潮使得每天有成千上万的人使用包含人工智能（AI）的应用。

## Artificial Intelligence  —  Human Intelligence Exhibited by Machines

## 人工智能——让机器展示出人类智能

![](https://blogs.nvidia.com/wp-content/uploads/2016/07/checkers_philip-taylor-1.jpg)

> King me: computer programs that played checkers were among the earliest examples of artificial intelligence, stirring an early wave of excitement in the 1950s.

> 介绍：玩跳棋的电脑程序是最早的人工智能的例子之一，在20世纪50年代激起了早期的人工智能兴奋浪潮。

Back in that summer of ’56 conference the dream of those AI pioneers was to construct complex machines — enabled by emerging computers — that possessed the same characteristics of human intelligence. This is the concept we think of as “General AI” —  fabulous machines that have all our senses (maybe even more), all our reason, and think just like we do. You’ve seen these machines endlessly in movies as friend —  C-3PO —  and foe —  The Terminator. General AI machines have remained in the movies and science fiction novels for good reason; we can’t pull it off, at least not yet.

回到1956年的达特茅斯会议，这些AI先驱的梦想就是构建具有与人类智慧相同特征的由当时新兴计算机构成的复杂机器。这个概念就是我们所说的“强人工智能（General AI）”，这是一个神话般的机器，具有我们所有的感觉（甚至更多），我们所有的理智，像我们一样想。你已经在电影中看到了这些机器，例如C-3PO （礼仪机器人）、敌人终结者等待。强人工智能（General AI）仍然存在于电影和科幻小说中，这是有原因的。我们不能实现强人工智能（General AI），至少现在还不能。


What we can do falls into the concept of “Narrow AI.” Technologies that are able to perform specific tasks as well as, or better than, we humans can. Examples of narrow AI are things such as image classification on a service like Pinterest and face recognition on Facebook.

目前我们能做的是有关“弱人工智能（Narrow AI）”的概念。这是一种能够执行特定任务的技术，或者比我们人类能做的更好的技术。例如，Pinterest利用AI进行图片分类，Facebook使用AI对脸部识别，这些都是“弱人工智能（Narrow AI）”的应用例子。

Those are examples of Narrow AI in practice. These technologies exhibit some facets of human intelligence. But how? Where does that intelligence come from? That get us to the next circle, Machine Learning.

这些都是对“弱人工智能（Narrow AI）”的实际实践。这些技术表现出人类智力的某些方面的特点。但是这些是如何实现的？这些智力来自哪里？带着问题我们将会来到下一个圆圈——机器学习。

## Machine Learning —  An Approach to Achieve Artificial Intelligence

## 机器学习——一种实现人工智能的方法

![](https://blogs.nvidia.com/wp-content/uploads/2016/07/spam_fit.jpg)

> Spam free diet: machine learning, a subset of AI (Artificial Intelligence) helps keep your inbox (relatively) free of spam.

> 垃圾邮件免费食谱:机器学习，人工智能的一个子集(人工智能)帮助你的收件箱(相对)不受垃圾邮件的影响。

Machine Learning at its most basic is the practice of using algorithms to parse data, learn from it, and then make a determination or prediction about something in the world. So rather than hand-coding software routines with a specific set of instructions to accomplish a particular task, the machine is “trained” using large amounts of data and algorithms that give it the ability to learn how to perform the task.

机器学习最基本的方法是使用算法来解析处理数据，从中学习，然后对世界中的某些事物做出决定或预测。因此，与其用特定的指令集编写软件程序来完成特定的任务，还不如使用大量的数据和算法“训练”机器，让它能够学习如何执行任务。

Machine learning came directly from minds of the early AI crowd, and the algorithmic approaches over the years included decision tree learning, inductive logic programming. clustering, reinforcement learning, and Bayesian networks among others. As we know, none achieved the ultimate goal of General AI, and even Narrow AI was mostly out of reach with early machine learning approaches.

机器学习的概念直接来源于早期的早期人工智能研究群体的思想。这些年来，算法的方法包括决策树学习、归纳逻辑编程、聚类、强化学习、贝叶斯网络等。 我们知道，没有一个人实现了“强人工智能（General AI）”的最终目标，甚至是通过早期的机器学习方法，甚至是“弱人工智能（Narrow AI）”都无法实现。

As it turned out, one of the very best application areas for machine learning for many years was computer vision, though it still required a great deal of hand-coding to get the job done. People would go in and write hand-coded classifiers like edge detection filters so the program could identify where an object started and stopped; shape detection to determine if it had eight sides; a classifier to recognize the letters “S-T-O-P.” From all those hand-coded classifiers they would develop algorithms to make sense of the image and “learn” to determine whether it was a stop sign.

事实证明，多年来机器学习的最佳应用领域之一是计算机视觉领域。要实现计算机视觉，它仍然需要大量的手工编码来完成工作。研究人员会去写手动编写分类器，比如边缘检测过滤器，这样程序就能识别出物体的起点和停止位置；形状检测确定是否有八面；识别字母“S-T-O-P”的分类器。从所有这些手工编写的分类器中，他们将开发算法来理解图像和学习识别图像，确定它是否是一个停止符号。

Good, but not mind-bendingly great. Especially on a foggy day when the sign isn’t perfectly visible, or a tree obscures part of it. There’s a reason computer vision and image detection didn’t come close to rivaling humans until very recently, it was too brittle and too prone to error.

这种办法可以使用，但并不是令人满意。尤其是在大雾天，当这个标志不是完全可见的时候，或者一棵树遮住了标志的某一部分，它的识别能力就会下降。计算机视觉和图像检测的能力直到最近才接近人类的原因是它太脆弱，太容易出错。

Time, and the right learning algorithms made all the difference.

时间，以及正确的学习算法让一切都变得不同。

## Deep Learning — A Technique for Implementing Machine Learning

## 深度学习——一种实现机器学习的技术
![](https://blogs.nvidia.com/wp-content/uploads/2016/07/orange_cat-1.jpg)

> Herding cats: Picking images of cats out of YouTube videos was one of the first breakthrough demonstrations of deep learning.

> 牧羊猫：从YouTube视频中挑选猫的图像是深入学习的第一个突破性示范之一。

Another algorithmic approach from the early machine-learning crowd, Artificial Neural Networks, came and mostly went over the decades. Neural Networks are inspired by our understanding of the biology of our brains – all those interconnections between the neurons. But, unlike a biological brain where any neuron can connect to any other neuron within a certain physical distance, these artificial neural networks have discrete layers, connections, and directions of data propagation.

“人工神经网络（Artificial Neural Networks）”是另外一种算法方法，它也是早期机器学习专家提出的，存在已经几十年了。神经网络的灵感来自于我们对大脑生物学构造的理解——所有这些神经元之间的相互联系。但是，不同之处在于任何神经元可以在一定的物理距离内连接到其他神经元的生物大脑，而人工神经网络具有离散的层、连接和数据传播方向。

You might, for example, take an image, chop it up into a bunch of tiles that are inputted into the first layer of the neural network. In the first layer individual neurons, then passes the data to a second layer. The second layer of neurons does its task, and so on, until the final layer and the final output is produced.

举个例子，你可以拿出一张图片，把它分割成一堆的小的图片碎片。它们被输入到神经网络的第一层。在第一层中单个独立神经元会将数据传递到第二层。第二层神经元同样会执行其任务，依此类推，直到产生最后一层，生成最终输出的结果。

Each neuron assigns a weighting to its input —  how correct or incorrect it is relative to the task being performed.  The final output is then determined by the total of those weightings. So think of our stop sign example. Attributes of a stop sign image are chopped up and “examined” by the neurons —  its octogonal shape, its fire-engine red color, its distinctive letters, its traffic-sign size, and its motion or lack thereof. The neural network’s task is to conclude whether this is a stop sign or not. It comes up with a “probability vector,” really a highly educated guess,  based on the weighting. In our example the system might be 86% confident the image is a stop sign, 7% confident it’s a speed limit sign, and 5% it’s a kite stuck in a tree ,and so on — and the network architecture then tells the neural network whether it is right or not.

每个神经元都将一个权重分配给它的输入，确定它与所执行任务的关系，对应正确与不正确的程度。最后的输出结果由这些权重的总和决定。以之前我们的停止标志为例子说明，我们将停止符号图像的属性切割，通过神经元来进行“检测”：它的八角形状，它的消防车类型的红色，它独特的字母，它的交通标志大小，以及它的手势。神经网络的任务是判断这个图像是否是一个停止标志。它提出了一个“概率向量”，一个基于权重的据理推测。在我们的例子中，神经网络系统可能有86%的概率确定图像是一个停止标志，7%的概率确认它是一个限速标志，5%的概率确认是一个被困在树上的风筝，等等。网络架构然后告诉神经网络结果是否正确。

Even this example is getting ahead of itself, because until recently neural networks were all but shunned by the AI research community. They had been around since the earliest days of AI, and had produced very little in the way of “intelligence.” The problem was even the most basic neural networks were very computationally intensive, it just wasn’t a practical approach. Still, a small heretical research group led by Geoffrey Hinton at the University of Toronto kept at it, finally parallelizing the algorithms for supercomputers to run and proving the concept, but it wasn’t until GPUs were deployed in the effort that the promise was realized.

即使是这样的例子也是超前的。因为直到最近，神经网络仍然被人工智能研究界所忽略。神经网络在人工智能发展的早期就出现了，但其几乎没有产生什么而“智力”。问题在于即使最基本的神经网络都是计算密集型的，因此这并不是一种实用的方法。尽管如此，由多伦多大学的Geoffrey Hinton领导的异端课题小组仍然坚持研究神经网络问题，最后在超级计算机中并行化算法来运行和证明这个概念，但一直到直到GPU的广泛部署应用后，这个承诺才被实现。

If we go back again to our stop sign example, chances are very good that as the network is getting tuned or “trained” it’s coming up with wrong answers —  a lot. What it needs is training. It needs to see hundreds of thousands, even millions of images, until the weightings of the neuron inputs are tuned so precisely that it gets the answer right practically every time — fog or no fog, sun or rain. It’s at that point that the neural network has taught itself what a stop sign looks like; or your mother’s face in the case of Facebook; or a cat, which is what Andrew Ng did in 2012 at Google.

如果我们再回到识别停止标志的例子。随着网络的调整或“训练”，结果就会变得更好。它会产生很多的错误答案，它需要的是更多的训练。研究人员需要收集成百上千，甚至上百万的图像，直到神经元输入的权重调整到精确，使得它几乎每次都能得到正确的答案——不管有雾或没有雾、是否有太阳或雨。此时神经网络已经学会判断停止符号的形式。神经网络还可以识别Facebook上你母亲的脸庞，或者识别出一只猫——这就是吴恩达（Andrew Ng）2012年在谷歌所做的事情。

Ng’s breakthrough was to take these neural networks, and essentially make them huge, increase the layers and the neurons, and then run massive amounts of data through the system to train it. In Ng’s case it was images from 10 million YouTube videos. Ng put the “deep” in deep learning, which describes all the layers in these neural networks.

吴恩达的突破之处在于：利用这些神经网络，本质上使它们变得巨大，增加了层和神经元，然后通过系统运行大量的数据来训练它。在吴恩达（Andrew Ng）的案例中，它是通过分析来自1000万段YouTube视频中的图片。吴恩达（Andrew Ng）真正实现了深度学习的“深度”，使得其能够描述神经网络中的所有的层次信息。


Today, image recognition by machines trained via deep learning in some scenarios is better than humans, and that ranges from cats to identifying indicators for cancer in blood and tumors in MRI scans. Google’s AlphaGo learned the game, and trained for its Go match —  it tuned its neural network —  by playing against itself over and over and over.

今天，在某些应用场景中，通过深入学习训练的机器获得的图像识别比人类识别的效果更好，例如识别猫、血液识别癌症、在MRI扫描中识别肿瘤等。谷歌的AlphaGo学习围棋，并通过围棋比赛来训练自己，同时反复与自己对抗来调整自己的神经网络。

## Thanks to Deep Learning, AI Has a Bright Future

## 感谢深度学习，人工智能有一个光明的未来

Deep Learning has enabled many practical applications of Machine Learning and by extension the overall field of AI. Deep Learning breaks down tasks in ways that makes all kinds of machine assists seem possible, even likely. Driverless cars, better preventive healthcare, even better movie recommendations, are all here today or on the horizon. AI is the present and the future. With Deep Learning’s help, AI may even get to that science fiction state we’ve so long imagined. You have a C-3PO, I’ll take it. You can keep your Terminator.

深入学习已经使机器学习有许多实际的应用同时扩展了人工智能（AI）的整体领域。深度学习以各种方式分解任务，这使得所有的机器辅助解决问题成为可能。无人驾驶汽车，更好的预防保健，甚至更好的电影推荐，都在今天或即将到来。AI既是现在，也是未来。在深度学习的帮助下，人工智能甚至可能达到我们长久以来所设想的科幻小说描述的水平。也许未来你会拥有自己的C-3PO，我将会拿走它，；你也可以保有自己的终结者。

## To learn more about where deep learning is going next, listen to our in-depth interview with AI pioneer Andrew Ng on the NVIDIA [AI Podcast](https://blogs.nvidia.com/ai-podcast/). 

## 想要更加深入了解深度学习的更多信息，在英伟达（NVIDIA）[AI播客](https://blogs.nvidia.com/ai-podcast/)听我们与人工智能先驱吴恩达（Andrew Ng）的深入访谈节目。 

# 写在最后

深度学习会在未来的各个新兴领域以及传统行业广泛实践应用。社会不断发展以及效率不断提升离不开对于各行各业的数据分析数据中蕴含的价值。

All in AI!

Learning English way is bumpy, let us join hands to advance together!

自动翻译也是深度学习的应用领域之一。

PS：自己对于在线翻译自动翻译的排名：Google >= 有道 >> 百度